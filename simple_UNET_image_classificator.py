# -*- coding: utf-8 -*-
"""ANDRES GHERSI SAYAN 20539425 HW4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RftodIwxpq_R5ONGAHwidB2ZTdjb_GSZ

ANDRES GHERSI SAYAN
20539425
HW4

QUESTION 1
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True, as_supervised=False)

train_dataset = dataset['train']
test_dataset = dataset['test']

print("\nDataset Oxford IIIT Pets:")
print(f"N of Samples for training: {info.splits['train'].num_examples}")
print(f"N of Sample for Test: {info.splits['test'].num_examples}")
print("\nDataset:")
for feature in info.features:
    print(f"- {feature}: {info.features[feature].shape}")

print("\nInfo:")
print(f"Name of classes: {info.features['label'].names}")
print(f"Description of dataset: {info.description}")

def mostrar_imagen_mascara(imagen, mascara):
    plt.figure(figsize=(10,5))

    plt.subplot(1,2,1)
    plt.imshow(imagen)
    plt.title("Image")
    plt.axis('off')

    plt.subplot(1,2,2)
    plt.imshow(mascara, cmap='gray')
    plt.title("Mask")
    plt.axis('off')

    plt.show()

print("\nSome samples:")
for ejemplo in train_dataset.take(3):
    imagen = ejemplo['image'].numpy()
    mascara = ejemplo['segmentation_mask'].numpy()
    mostrar_imagen_mascara(imagen, mascara)

import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 100

def preprocess_data(datapoint):
    image = datapoint['image']
    mask = datapoint['segmentation_mask']

    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
    mask = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE), method='nearest')

    image = tf.cast(image, tf.float32) / 255.0
    mask = tf.cast(mask < 2, tf.float32)

    return image, mask

dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)

train_dataset = dataset['train'].map(preprocess_data).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_dataset = dataset['test'].map(preprocess_data).cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

def unet_model(img_size):
    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))

    c1 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)
    c1 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c1)
    p1 = tf.keras.layers.MaxPooling2D()(c1)

    c2 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(p1)
    c2 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c2)
    p2 = tf.keras.layers.MaxPooling2D()(c2)

    b1 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p2)
    b1 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(b1)

    u1 = tf.keras.layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(b1)
    u1 = tf.keras.layers.concatenate([u1, c2])
    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u1)
    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c3)

    u2 = tf.keras.layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(c3)
    u2 = tf.keras.layers.concatenate([u2, c1])
    c4 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(u2)
    c4 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c4)

    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid', padding='same')(c4)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

def simple_segmentation_model(img_size):
    inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3))

    x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)
    x = tf.keras.layers.MaxPooling2D()(x)
    x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)
    x = tf.keras.layers.MaxPooling2D()(x)
    x = tf.keras.layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)
    x = tf.keras.layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)

    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid', padding='same')(x)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

model = simple_segmentation_model(IMG_SIZE)
model_unet = unet_model(IMG_SIZE)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_dataset, validation_data=test_dataset, epochs=EPOCHS)
history_unet = model.fit(train_dataset, validation_data=test_dataset, epochs=EPOCHS)

# Model
def display(display_list):
    plt.figure(figsize=(15, 15))

    title = ['Image', 'Mask Graound Truth', 'Predict']

    for i in range(len(display_list)):
        plt.subplot(1, len(display_list), i+1)
        plt.title(title[i])
        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))
        plt.axis('off')
    plt.show()

for images, masks in test_dataset.take(1):
    predictions = model.predict(images)
    for i in range(3):
        display([images[i], masks[i], predictions[i]])


# Model UnET
for images, masks in test_dataset.take(1):
    predictions = model_unet.predict(images)
    for i in range(3):
        display([images[i], masks[i], predictions[i]])

def plot_history(histories, labels):
    plt.figure(figsize=(14, 5))

    plt.subplot(1, 2, 1)
    for history, label in zip(histories, labels):
        plt.plot(history.history['loss'], label=f'{label} - Loss')
        plt.plot(history.history['val_loss'], '--', label=f'{label} - Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss per Epoch')

    plt.subplot(1, 2, 2)
    for history, label in zip(histories, labels):
        plt.plot(history.history['accuracy'], label=f'{label} - Accuracy')
        plt.plot(history.history['val_accuracy'], '--', label=f'{label} - Val Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Accuracy per Epoch')

    plt.show()

plot_history([history_unet, history], ['U-Net', 'Simple CNN'])

"""QUESTION 2"""

!pip install tensorflow tensorflow_datasets

import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models

dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)
train_ds = dataset['train']
test_ds = dataset['test']

def preprocess(data):
    image = tf.image.resize(data['image'], (128, 128))
    segmentation_mask = tf.image.resize(data['segmentation_mask'], (128, 128))

    binary_mask = tf.where(segmentation_mask > 0, 1, 0)
    binary_mask = binary_mask[:, :, 0]

    indices = tf.where(tf.equal(binary_mask, 1))
    y_min = tf.reduce_min(indices[:,0])
    y_max = tf.reduce_max(indices[:,0])
    x_min = tf.reduce_min(indices[:,1])
    x_max = tf.reduce_max(indices[:,1])
    bbox = tf.cast([x_min, y_min, x_max, y_max], tf.float32) / 128.0

    image = image / 255.0

    return image, bbox

train_data = train_ds.map(preprocess)
test_data = test_ds.map(preprocess)

train_data = train_data.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)
test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)

model = models.Sequential([
    layers.Conv2D(16, 3, activation='relu', input_shape=(128,128,3)),
    layers.MaxPooling2D(),
    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(4)
])

# IoU metric
def compute_iou(y_true, y_pred):
    y_true = tf.clip_by_value(y_true, 0, 1)
    y_pred = tf.clip_by_value(y_pred, 0, 1)

    x1_true, y1_true, x2_true, y2_true = tf.split(y_true, 4, axis=-1)
    x1_pred, y1_pred, x2_pred, y2_pred = tf.split(y_pred, 4, axis=-1)

    x1_inter = tf.maximum(x1_true, x1_pred)
    y1_inter = tf.maximum(y1_true, y1_pred)
    x2_inter = tf.minimum(x2_true, x2_pred)
    y2_inter = tf.minimum(y2_true, y2_pred)

    inter_area = tf.maximum(0.0, x2_inter - x1_inter) * tf.maximum(0.0, y2_inter - y1_inter)
    true_area = (x2_true - x1_true) * (y2_true - y1_true)
    pred_area = (x2_pred - x1_pred) * (y2_pred - y1_pred)

    union_area = true_area + pred_area - inter_area
    iou = inter_area / (union_area + 1e-7)
    return iou

def iou_metric(y_true, y_pred):
    iou = compute_iou(y_true, y_pred)
    return tf.reduce_mean(iou)

model.compile(optimizer='adam', loss='mse', metrics=['mae', iou_metric])
history = model.fit(train_data, epochs=10, validation_data=test_data)

plt.figure(figsize=(18,5))

plt.subplot(1,3,1)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.title('Loss per epoch')

plt.subplot(1,3,2)
plt.plot(history.history['mae'], label='train MAE')
plt.plot(history.history['val_mae'], label='val MAE')
plt.legend()
plt.title('MAE per epoch')

plt.subplot(1,3,3)
plt.plot(history.history['iou_metric'], label='train IoU')
plt.plot(history.history['val_iou_metric'], label='val IoU')
plt.legend()
plt.title('IoU per epoch')

plt.show()